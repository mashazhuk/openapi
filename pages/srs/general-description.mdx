---
title: General Description
---

This system is designed to automatically analyze human speech in order to detect the speakerâ€™s emotional state (e.g., happiness, sadness, anger) using modern speech processing and neural network technologies.

### Objectives:
- Develop an emotion detection engine based on audio input
- Apply machine hearing techniques and acoustic signal analysis
- Implement a REST API to process and return emotional classification results

### Target Users:
- AI and machine learning researchers
- Voice interface developers
- Psychodiagnostics specialists

### Key Features:
- Upload audio recordings (`.wav`, `.mp3`)
- Signal pre-processing (noise removal, normalization)
- Feature extraction (e.g., MFCC, spectrogram)
- Emotion classification using a trained neural network
- JSON output via REST API

### Benefits:
- Enables emotion-aware systems
- Improves human-computer interaction
- Supports accessibility and assistive technologies

